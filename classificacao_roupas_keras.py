# -*- coding: utf-8 -*-
"""classificacao_roupas_keras

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOfYIQsiPMbJMWgi21CHe7VgHEVOtfoE
"""

pip install tensorflow==2.1

#IMPORTS
import tensorflow
from tensorflow import keras 
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import load_model

"""CARREGAR O DATASET"""

#importando o dataset retirado do keras
dataset = keras.datasets.fashion_mnist

#atribuindo as imagens para grupo de treino e grupo de teste
((imagens_treino, identificacoes_treino), (imagens_teste, identificacoes_teste)) = dataset.load_data()

"""EXPLORANDO O DATASET"""

#verificando a quantidade de imagens e o tamanho das imagens (qtd, tamanho x, tamanho y)
imagens_treino.shape
imagens_teste.shape

#confirmando se as identificaçoes tem a mesma qtd de imagens
len(imagens_treino)
len(identificacoes_treino)

#demonstrando as imagens em um grafico de pixels com matplot
plt.imshow(imagens_treino[3])

"""DENOMINANDO AS CLASSIFICAÇÕES"""

#identificação minima de classificação
identificacoes_treino.min()

#identificação maxima de classificação
identificacoes_treino.max()

total_de_classificacoes = 10
nomes_de_classificacoes = ['Camiseta', 'Calca', 'Moletom', 'Vestido', 'Casaco', 'Sandalia',
                           'Camisa', 'Tenis', 'Bolsa', 'Bota']

for imagem in range(10):
  #diminuir a dimensao do grafico para exibir menor
  plt.subplot(2, 5, imagem+1)

  #demonstrar as imagens
  plt.imshow(imagens_treino[imagem])

  #assimilar titulo da classificação com as imagens
  plt.title(nomes_de_classificacoes[identificacoes_treino[imagem]], )

"""NORMALIZAÇÃO DAS IMAGENS"""

imagens_treino = imagens_treino/float(255)

"""CRIANDO, COMPILANDO, TREINANDO E NORMALIZANDO O MODELO"""

#sequential: executando operações em sequencia(entrada, processamento, saida)
modelo = keras.Sequential([
  #dados de entrada: input_shape(dimensoes da imagem)
  #layers: achatando a imagem para uma só camada. Uma linha por x colunas
  #ENTRADA
  #CAMADA 0
  keras.layers.Flatten(input_shape=(28,28)),

  #PROCESSAMENTO
  #CAMADA 1/ Camadas ocultas
  #dense: mesclando o processamento das entradas, 256 - numero relativo multiplo de 2
  #ativação por relu: relu significa q entradas de valores negativos serao 0, e valores positivos serao analisados
  #Função nao Linear (analisando sem um resultado linear)
  #nn - neural networks - redes neurais
  keras.layers.Dense(256, activation=tensorflow.nn.relu),

  #afunilar processamento 
  #keras.layers.Dense(128, activation=tensorflow.nn.relu),
  #keras.layers.Dense(64, activation=tensorflow.nn.relu),
  

  #adormecendo celulas
  keras.layers.Dropout(0.2),

  #SAIDA
  #CAMADA 2
  #analisando por categorias (10) numero da camada de saída  
  #softmax=probabilidade de estar correta a identificação comparando as categorias pelas imagens
  #para cada categoria, uma probabilidade de acerto
  #Compara as imagens com as categorias, identifica um percentual de acerdo para cada categoria e soma, o total é igual a 1
  keras.layers.Dense(10, activation=tensorflow.nn.softmax)
])

#compilar o modelo
#O QUE É ADAM? categorizar por mais de uma categoria

#optimizer=melhorando o treino
#loss= perda por vinculacao de categoria errada
#metrics=acuracia, metrica de acertos

modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

#treinando mais de uma vez
#validation_split = validação separada 
historico = modelo.fit(imagens_treino, identificacoes_treino, epochs=5, validation_split=0.2)

"""SALVANDO O MODELO"""

modelo.save('modelo.h5')
modelo_salvo = load_model('modelo.h5')

historico.history

"""GRÁFICOS DE ANÁLISE DE ACURÁCIA"""

#se o treino ta maior q a validação: overfit
#se o treino ta menor a validacao: underfit

plt.plot(historico.history['accuracy'])
plt.plot(historico.history['val_accuracy'])
plt.title('Acuária por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend(['treino', 'validação'])

"""GRAFICO DE ANÁLISE PERDA"""

plt.plot(historico.history['loss'])
plt.plot(historico.history['val_loss'])
plt.title('Acuária por Épocas')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend(['treino', 'validação'])

testes = modelo.predict(imagens_teste)
#argmax: analisa o resultado dentro de um retorno de array variante de 0 a 1
print('resultado:', np.argmax(testes[5]))
print('valor correto:', identificacoes_teste[5])

testes_modelo_salvo = modelo_salvo.predict(imagens_teste)
print('resultado modelo salvo:', np.argmax(testes_modelo_salvo[5]))
print('valor correto:', identificacoes_teste[5])

perda_teste, acuracia_teste = modelo.evaluate(imagens_teste, identificacoes_teste)
print('perda:', perda_teste)
print('acuracia:', acuracia_teste)